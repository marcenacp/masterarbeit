\chapter{Conclusion}
\label{sec:conclusion}

In the present thesis, we were to apply canonical methods of machine and deep learning (such as feature engineering, metrics selection and hyperparameter optimization) to simultaneously localize and classify environmental sounds. After extracting adapted features from regular audio recordings, proper training and testing datasets were prepared for both clean and mixed sounds. Specific evaluation metrics were picked to tackle a multiclass multilabel classification problem. The machine-hearing agent is based on convolutional neural networks whose architectures were iteratively determined through random search.

The real-scenario's complexity (with a variable number of sounds from more identification classes at different azimuths), as well as the presence of reverberation and the strong dataset imbalance make the learning process much more difficult than in the case of clean sounds where we achieve very good levels of accuracy for both identification (88.8\% accuracy) and localization (88.7\% accuracy). For mixed sounds, localization turned out a much harder task (53.2\% balanced accuracy on average) while much better results were achieved for identification (65.0\% balanced accuracy on average).

Further investigations can be done in the future, especially to achieve better results when dealing with mixed sounds. One possibility would be to use deeper networks or longer training time with lowered learning rates. The fact that some localization classes clearly stand out in terms of balanced accuracy indicate better results can also be achieved for other azimuths. Dataset imbalance for mixed sounds was proven to play a role in the poorer results for the localization of some azimuths, so gathering more data for the outnumbered localization classes could help reach better results. Another possibility for achieving better results is to make use of more regularization. An idea for regularization is to convolve in the channel's direction for AMS and ILD features before convolving on each spectrogram.
One could also explore feature transferability by expanding the experiments from section~\ref{sec:results:multi}. In particularly, testing several architectures with multiple random initializations could lead to broader conclusions on layers roles in function of their depths.