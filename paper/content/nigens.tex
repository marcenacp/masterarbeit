@Pierre: This text describes the NIGENS database. You can use the information here but don't copy-paste as is. Integrate this information into your text where you describe the sound data.

The input to this scene generation were the sounds of the NIGENS database, which we collected to this aim. The database provides audio files of fourteen different event classes: running engine, crash, footsteps, piano, barking dog, phone, knocking, burning fire, crying baby, alarm, female speech, male speech, screams, and a ``general'' class. Most of those sounds were attained from a commercial stock sound provider (\url{stockmusic.com}), the speech classes from the GRiD and TIMIT corpora \cite{Cooke2006audio, Garofolo1993timit}, and the scream sounds plus a few general sounds from \url{freesound.org}. The NIGENS database contains $1050$ wav files, $305$ of which are in the ``general'' class -- an ``anything else but the thirteen provided regular types'' class with sounds chosen to exhibit as much variety as possible, e.g. including nature sounds such as wind, rain, or animals, sounds from man-made environments such as honks, doors, or guns, as well as human sounds like coughs. All audio files contain sound events in isolation, i.e. without superposition of ambient sounds or other sources. All sound files were manually annotated by us for on- and offsets of sound events. 

For .bib
@article{Cooke2006audio,
  title={An audio-visual corpus for speech perception and automatic speech recognition},
  author={Cooke, Martin and Barker, Jon and Cunningham, Stuart and Shao, Xu},
  journal={The Journal of the Acoustical Society of America},
  volume={120},
  number={5},
  pages={2421--2424},
  year={2006},
  publisher={Acoustical Society of America}
}

@article{Garofolo1993timit,
  title={TIMIT Acoustic-Phonetic Continuous Speech Corpus LDC93S1},
  author={John Garofolo et al.},
  journal={Web Download, Philadelphia: Linguistic Data Consortium},
  year={1993}
}